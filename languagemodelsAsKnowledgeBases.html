<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2023-06-16 周五 10:04 -->
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Language Models as Knowledge Bases?</title>
<meta name="author" content="Zi Liang" />
<meta name="generator" content="Org Mode" />
<link rel='stylesheet' type='text/css' href='https://gongzhitaao.org/orgcss/org.css'/>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Language Models as Knowledge Bases?</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgeac6223">1. 相关benchmark及对应效果</a></li>
<li><a href="#org28c4b52">2. 相关工作</a>
<ul>
<li><a href="#org5666cb0">2.1. Language Models as Knowledge Bases? ‘19</a></li>
<li><a href="#orga4afd01">2.2. Neural Databases '20</a></li>
<li><a href="#orgd785623">2.3. Can Prompt Probe Pretrained Language Models? Understanding the Invisible Risks from a Causal View ACL'22</a></li>
</ul>
</li>
</ul>
</div>
</div>


<div id="outline-container-orgeac6223" class="outline-2">
<h2 id="orgeac6223"><span class="section-number-2">1.</span> 相关benchmark及对应效果</h2>
<div class="outline-text-2" id="text-1">
<p>
LAMA
</p>
</div>
</div>


<div id="outline-container-org28c4b52" class="outline-2">
<h2 id="org28c4b52"><span class="section-number-2">2.</span> 相关工作</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-org5666cb0" class="outline-3">
<h3 id="org5666cb0"><span class="section-number-3">2.1.</span> Language Models as Knowledge Bases? ‘19</h3>
<div class="outline-text-3" id="text-2-1">
<p>
出发点：构建并使用KB需要一个完整的麻烦的pipeline，如果LM在语法知识之外还可以学会文档中的关系型知识，那么就不需要如此麻烦。该论文试图探究：LM预训练模型中是否含有关系型知识？和已有的方法比效果如何？
</p>


<div id="org656fcb1" class="figure">
<p><img src="./images/screenshot_20221124_171406.png" alt="screenshot_20221124_171406.png">   
</p>
</div>


<p>
结论：
</p>
<ol class="org-ol">
<li>即使不做微调，LM里面也含有关系型的知识</li>
<li>BERT通过完形填空任务做QA，效果还是挺好的</li>
</ol>


<p>
该文属于开山之作，提出了这种可能
</p>
</div>
</div>

<div id="outline-container-orga4afd01" class="outline-3">
<h3 id="orga4afd01"><span class="section-number-3">2.2.</span> Neural Databases '20</h3>
<div class="outline-text-3" id="text-2-2">
<p>
出发点：LM能否作为数据库来用，即我们通过自然语言进行数据库的一系列操作，诸如查询、更新、删除等等。
</p>

<p>
作者首先测试了当前的LM的效果，发现：1）在slect-project-join querys 上够用，如果已经拥有了对应的事实；2）在一些特殊操作（no-trival databases）或聚合操作的查询上，不太够用。
</p>

<p>
为此作者自己提出了一套architecture（NeuralDB）解决这个问题。输入大概是这个样子：
</p>


<div id="org722f5c6" class="figure">
<p><img src="./images/screenshot_20221124_172725.png" alt="screenshot_20221124_172725.png"> 
</p>
</div>

<p>
可以看出，这其实也就是非结构化的知识信息。
</p>

<p>
模型的推理时刻表示图，backbone是t5
</p>


<div id="org9e021e2" class="figure">
<p><img src="./images/screenshot_20221124_172829.png" alt="screenshot_20221124_172829.png"> 
</p>
</div>

<p>
作者统计了在各种数据库查询问题上的结果，如下：
</p>


<div id="org302fb39" class="figure">
<p><img src="./images/screenshot_20221124_173016.png" alt="screenshot_20221124_173016.png"> 
</p>
</div>


<p>
于是作者自己搞了一个模型（NeuralDB），总体上看，就是加了一些trick，效果图如下：
</p>


<div id="orgc328d67" class="figure">
<p><img src="./images/screenshot_20221124_173154.png" alt="screenshot_20221124_173154.png">
</p>
</div>

<p>
具体流程就是，通过检索获得一些支撑集合。然后动过比对这些支撑集合来生成答案。最终通过聚合器聚合这些答案，得到最终的结果。
</p>

<p>
之前写过一篇笔记，见：<a href="https://liangzid.github.io/paper_reading/neural_database.html">https://liangzid.github.io/paper_reading/neural_database.html</a>
</p>
</div>
</div>


<div id="outline-container-orgd785623" class="outline-3">
<h3 id="orgd785623"><span class="section-number-3">2.3.</span> Can Prompt Probe Pretrained Language Models? Understanding the Invisible Risks from a Causal View ACL'22</h3>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Date: Thu Nov 24 16:42:04 2022</p>
<p class="author">Author: Zi Liang</p>
<p class="date">Created: 2023-06-16 周五 10:04</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>