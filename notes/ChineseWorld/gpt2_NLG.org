#+title: 关于huggingface transformers NLG模块实现的基本思路
#+author: liangzid
#+date: Wed Nov 17 19:40:30 2021
#+email: 2273067585@qq.com 
#+latex_class: elegantpaper 
* 标题1
* 关于huggingface transformers NLG 模块实现的基本思路
** 语言模型的训练与测试的不同之处
PLM的训练，依愚所见，多半是token级别groundtruth的思路，即预测下一个token时，基于的是前面的token全都正确的似然假设；
而其测试时，则没有了groud truth的强假设，而是在预测的基础上再预测。

后者比较好理解，因为实际应用场景下没有标签嘛。但是前者呢?前者是一种较为死板的训练方式，因为这样做把PLM限制的太死了，
不过常常也是无奈之举罢了。明白了这种不同之处，就能设计对应的数据集进行实验了。

** 训练环节
*** 数据集封装形式
一般而言，是数据等于标签的格式。以对话为例，可能就是"Q+[SEP]+A"这种。
*** 微不足道的模型训练细节
由于是token预测问题，所以本质上属于一个分类问题，一般而言，会使用交叉熵，除了使用transformers库之外，还可以自己用以下的方式进行损失的定义和传播：

#+BEGIN_SRC python
  loss_func_cls = CrossEntropyLoss(ignore_index=PAD_ID, reduction='sum')
  output_distributions=Decoder(utterance_input)[0]
  output_prediction=output_distributions.permute([0,2,1])
  loss_autoencoder=loss_func_cls(output_prediction,utterance_input)
#+END_SRC
变量名的意义很有问题，不过所表达的训练细节的意思，是对的。
** 测试环节
*** 数据集封装形式
测试环节的数据集同训练环节有所不同，因为在测试环节，相当于是基于一个prefix去生成后面的话。
所以，数据集的数据，应该是：“Q+[SEP]”，标签同样是“Q+[SEP]+A”。
*** NLG生成细节
    下面给出几种较为常见的NLG的具体实现，方便日后炼丹之用。
**** 贪婪生成方案

     #+BEGIN_SRC python
       beam_outputs=Decoder.generate(input_ids=utterance_input, max_length=64)
     #+END_SRC
注意，这个utterance_input的长度是需要小于最大长度的，前者生成完成后的句子长度最大为max_length。

**** beam search 方案

     #+BEGIN_SRC python
       outputs=Decoder.generate(input_ids=utterance_input, max_length=64,
						       num_beams=5,
						       num_return_sequences=5, early_stopping=True)
     #+END_SRC

**** 其他方案
参考这里： https://huggingface.co/blog/how-to-generate







