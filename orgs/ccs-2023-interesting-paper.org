#+title: Interesting Researches of AI security in CCS 2023
#+date: Sat Dec 30 21:06:13 2023
#+author: Zi Liang
#+email: zi1415926.liang@connect.polyu.hk
#+latex_class: elegantpaper
#+filetags: ::



** AIGC Related
*** DONE Evading Watermark based Detection of AI-Generated Content
CLOSED: [2023-12-30 Sat 21:26]
+ https://dl.acm.org/doi/10.1145/3576915.3623189
+ a method to bypass (evading) the watermark-based AIGC detection.
*** TODO DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image Generation Models
+ https://arxiv.org/abs/2210.06998
*** TODO Protecting Intellectual Property of Language Generation APIs with Lexical Watermark
+ https://arxiv.org/abs/2112.02701

** Relevant to my field and interesting
*** DONE Do Users Write More Insecure Code with AI Assistants?
CLOSED: [2023-12-30 Sat 21:27]
+ https://dl.acm.org/doi/abs/10.1145/3576915.3623157
+ Overall, we find that participants who had access to an AI assistant wrote significantly less secure code than those without access to an assistant. Participants with access to an AI assistant were also more likely to believe they wrote secure code, suggesting that such tools may lead users to be overconfident about security flaws in their code.
*** TODO Unsafe Diffusion: On the Generation of Unsafe Images and Hateful Memes From Text-To-Image Models
+ https://dl.acm.org/doi/10.1145/3576915.3616679
*** REVIEW Stealing the Decoding Algorithms of Language Models
+ https://dl.acm.org/doi/10.1145/3576915.3616652

** Not relevant but interesting and maybe valuable
*** TODO P-Forward: Fine-tuning and Inference on Language Models with Differential Privacy in Forward Pass
+ https://dl.acm.org/doi/10.1145/3576915.3616592
*** TODO Stolen Risks of Models with Security Properties
+ https://dl.acm.org/doi/10.1145/3576915.3616653









